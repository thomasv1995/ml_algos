{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a536967d-74c1-4c21-9a39-64de04e86975",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=G45TuC6zRf4&list=PLTl9hO2Oobd97qfWC40gOSU8C0iu0m2l4&index=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7979db2-d0ea-49f8-829b-e843c9a46054",
   "metadata": {},
   "source": [
    "<img src=\"../pictures/layer_norm.png\" alt=\"pic\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a00a3-404c-48fa-b680-7837e18ee5ec",
   "metadata": {},
   "source": [
    "Here we focus on the first \"Add & Norm\" layer of the Encoder. This layer takes as input the output matrix of the first Multi-head attention block. It also has a residual connection from the input to the Encoder + Positional Embeddings. These residuals connections are added to ensure that is a stronger information signal that flows trhough Deep Networks and to prevent loss of information in backpropagation from vanishing gradients (gradient updates become 0). It ensures stable training and better convergence.\n",
    "\n",
    "There in Layer Add & Norm we \"Add\" the output of the Multi-Headed attention block and the input + positional encodings together and pass the result to a Normalization Layer.\n",
    "\n",
    "During Normalization, the activation values in each neuron adjusted such that their mean is 0 and their standard deviation is 1 (relative to its layer). So for every activation value:\n",
    "\n",
    "$$a_i =f[W_{i}^{T}, x+b_i]$$\n",
    "\n",
    "We normalize by:\n",
    "$$y =\\gamma_l[\\frac{a_i-\\mu_i}{\\sigma_i}] + \\beta_l$$\n",
    "\n",
    "where $i$ represents the $i$th activation neuron, and $l$ the $l$th layer\n",
    "\n",
    "$\\gamma$ and $\\beta$ are learnable parameters, there is one pair per layer. However, the mean and std are computed for each word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f1896f-c0dc-463e-9ebe-53b182eee41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f7ac0a7-5962-4359-ac90-f14135b855d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])\n",
    "# B = batch size, S = number of words in max sequence, E = embedding\n",
    "B, S, E = inputs.size()\n",
    "inputs = inputs.reshape(S, B, E)\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0df5ba1-2e69-45e6-b450-7501b1bfb343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2000, 0.1000, 0.3000]],\n",
       "\n",
       "        [[0.5000, 0.1000, 0.1000]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73eb2bd-9275-4cd7-b327-5566b0eb2779",
   "metadata": {},
   "source": [
    "Layer normalization is actually computed across layer and batch. Therefore, we get distinct pairs of $\\gamma$ and $\\beta$ for each layer-batch combination : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b2fd197-1d05-47a1-a77e-670215553f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_shapes = inputs.size()[-2:]\n",
    "gamma = nn.Parameter(torch.ones(parameter_shapes))\n",
    "beta = nn.Parameter(torch.zeros(parameter_shapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cae654e8-16cb-415d-883b-74065cd1504b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.size(), beta.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3beee9a8-e291-4316-86d0-7bdc1172b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute dimensions for which we want to perform layer normalization (that is the batch + the embedding dimensions)\n",
    "# hint: its the last two layers\n",
    "dims = [-(i+1) for i in range(len(parameter_shapes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "986d6def-7c85-4c52-8ccf-de44309e845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f83b6755-fdf3-4093-bee4-11ebbc484ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = inputs.mean(dim=dims, keepdim=True)\n",
    "mean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8629ef05-6e32-4c60-bd3a-ad8affd46ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2000]],\n",
       "\n",
       "        [[0.2333]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5ab4a35-377a-4fc6-8d2e-fc0378b709ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ((inputs - mean)**2).mean(dim=dims, keepdim=True)\n",
    "# ensure std isn't 0 since it is the denominator\n",
    "epsilon = 1e-5\n",
    "std = (var + epsilon).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f86f92b3-7f40-439c-b8c7-69cb4e72b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (inputs - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af4b9c5b-81e7-436e-916d-697f83777e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = gamma *y + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "63317f23-5d18-4bfe-b62a-bbb7099156d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29d9c161-01c5-491e-87c4-b946ca858989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206d8bc-65c4-43e8-b075-ba1c20a4756a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5924941a-ceee-479f-94e6-0d439a9e751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization:\n",
    "    def __init__(self, parameters_shape, eps=1e-5):\n",
    "        self.parameters_shape = parameters_shape\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # compute dimensions for which we want to perform layer normalization (that is the batch + the embedding dimensions)\n",
    "        # hint: its the last two layers\n",
    "        dims = [-(i+1) for i in range(len(self.parameters_shape))]\n",
    "        mean = inputs.mean(dim=dims, keepdim=True)\n",
    "        print(f\"Mean \\n ({mean.size()}): \\n {mean})\")\n",
    "        var = ((inputs - mean)**2).mean(dim=dims, keepdim=True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        print(f\"Std \\n ({std.size()}): \\n {std})\")\n",
    "        y = (inputs - mean) / std\n",
    "        print(f\"y \\n ({y.size()}): \\n {y})\")\n",
    "        out = self.gamma * y + self.beta\n",
    "        print(f\"Output \\n ({out.size()}): \\n {out})\")\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b5f3fc7-5a2d-4872-884a-372cc5cb218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "sentence_length = 5\n",
    "embedding_dim = 8\n",
    "inputs = torch.randn(sentence_length, batch_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e5ad0ca-ad10-40ed-b968-2888cbb90a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter(torch.ones(inputs.size()[-2:])).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b13e2159-c7be-4d7a-ab96-50cf6ae6cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = LayerNormalization(parameters_shape=inputs.size()[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "00ebc987-5abc-4fa1-9b7f-1538f01ee44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean \n",
      " (torch.Size([5, 1, 1])): \n",
      " tensor([[[ 0.1247]],\n",
      "\n",
      "        [[ 0.1336]],\n",
      "\n",
      "        [[-0.0469]],\n",
      "\n",
      "        [[-0.1399]],\n",
      "\n",
      "        [[ 0.1343]]]))\n",
      "Std \n",
      " (torch.Size([5, 1, 1])): \n",
      " tensor([[[0.8218]],\n",
      "\n",
      "        [[1.0480]],\n",
      "\n",
      "        [[0.9055]],\n",
      "\n",
      "        [[1.2428]],\n",
      "\n",
      "        [[1.0522]]]))\n",
      "y \n",
      " (torch.Size([5, 3, 8])): \n",
      " tensor([[[-0.1071,  1.3647, -0.7985, -1.2234, -1.3445,  0.3726, -0.6062,\n",
      "          -0.9186],\n",
      "         [-1.4119,  1.1061,  1.5628, -0.2964,  2.0020,  0.3794, -0.5848,\n",
      "          -0.5192],\n",
      "         [ 0.6890, -0.4799, -0.6190,  0.5880,  0.8222,  1.6510, -1.0985,\n",
      "          -0.5298]],\n",
      "\n",
      "        [[ 1.0896, -0.8622,  1.3571,  0.5579, -0.4322,  1.1513,  1.4784,\n",
      "          -0.9235],\n",
      "         [-1.1008, -0.6334,  0.2749, -0.1975,  0.0471,  0.3669,  0.7266,\n",
      "           0.4657],\n",
      "         [-0.8278, -0.1707, -1.5194, -0.2840, -1.8340,  1.5010, -1.5312,\n",
      "           1.3004]],\n",
      "\n",
      "        [[ 0.2462, -1.0931, -1.5495, -1.4534,  1.6599,  0.3497,  1.5365,\n",
      "          -1.3019],\n",
      "         [-0.1945,  0.5511,  0.4614, -1.3758, -1.5687,  0.0930,  0.5842,\n",
      "           0.7743],\n",
      "         [ 0.6928,  0.4164,  0.4343, -1.5143,  0.2965,  0.8982, -0.1242,\n",
      "           1.1810]],\n",
      "\n",
      "        [[ 0.5049,  0.7949, -0.1415,  0.0268, -0.4009,  0.8883, -0.3975,\n",
      "          -1.7064],\n",
      "         [ 0.4681,  0.9660, -0.7651, -1.2775, -1.3326,  0.7993,  1.5216,\n",
      "           0.8115],\n",
      "         [ 0.1326,  0.9304,  0.5280, -1.9095,  1.2970, -1.9442,  0.2108,\n",
      "          -0.0048]],\n",
      "\n",
      "        [[-0.7120, -2.1700, -0.0327, -0.0042,  0.3492, -0.4640, -0.3542,\n",
      "           1.8036],\n",
      "         [-0.8564,  0.4667,  0.0869,  1.8223, -0.4604,  0.7509, -0.6126,\n",
      "          -1.1521],\n",
      "         [ 0.1414,  0.3553,  1.3234,  0.6619,  0.1995, -0.6199,  1.3838,\n",
      "          -1.9064]]]))\n",
      "Output \n",
      " (torch.Size([5, 3, 8])): \n",
      " tensor([[[-0.1071,  1.3647, -0.7985, -1.2234, -1.3445,  0.3726, -0.6062,\n",
      "          -0.9186],\n",
      "         [-1.4119,  1.1061,  1.5628, -0.2964,  2.0020,  0.3794, -0.5848,\n",
      "          -0.5192],\n",
      "         [ 0.6890, -0.4799, -0.6190,  0.5880,  0.8222,  1.6510, -1.0985,\n",
      "          -0.5298]],\n",
      "\n",
      "        [[ 1.0896, -0.8622,  1.3571,  0.5579, -0.4322,  1.1513,  1.4784,\n",
      "          -0.9235],\n",
      "         [-1.1008, -0.6334,  0.2749, -0.1975,  0.0471,  0.3669,  0.7266,\n",
      "           0.4657],\n",
      "         [-0.8278, -0.1707, -1.5194, -0.2840, -1.8340,  1.5010, -1.5312,\n",
      "           1.3004]],\n",
      "\n",
      "        [[ 0.2462, -1.0931, -1.5495, -1.4534,  1.6599,  0.3497,  1.5365,\n",
      "          -1.3019],\n",
      "         [-0.1945,  0.5511,  0.4614, -1.3758, -1.5687,  0.0930,  0.5842,\n",
      "           0.7743],\n",
      "         [ 0.6928,  0.4164,  0.4343, -1.5143,  0.2965,  0.8982, -0.1242,\n",
      "           1.1810]],\n",
      "\n",
      "        [[ 0.5049,  0.7949, -0.1415,  0.0268, -0.4009,  0.8883, -0.3975,\n",
      "          -1.7064],\n",
      "         [ 0.4681,  0.9660, -0.7651, -1.2775, -1.3326,  0.7993,  1.5216,\n",
      "           0.8115],\n",
      "         [ 0.1326,  0.9304,  0.5280, -1.9095,  1.2970, -1.9442,  0.2108,\n",
      "          -0.0048]],\n",
      "\n",
      "        [[-0.7120, -2.1700, -0.0327, -0.0042,  0.3492, -0.4640, -0.3542,\n",
      "           1.8036],\n",
      "         [-0.8564,  0.4667,  0.0869,  1.8223, -0.4604,  0.7509, -0.6126,\n",
      "          -1.1521],\n",
      "         [ 0.1414,  0.3553,  1.3234,  0.6619,  0.1995, -0.6199,  1.3838,\n",
      "          -1.9064]]], grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1071,  1.3647, -0.7985, -1.2234, -1.3445,  0.3726, -0.6062,\n",
       "          -0.9186],\n",
       "         [-1.4119,  1.1061,  1.5628, -0.2964,  2.0020,  0.3794, -0.5848,\n",
       "          -0.5192],\n",
       "         [ 0.6890, -0.4799, -0.6190,  0.5880,  0.8222,  1.6510, -1.0985,\n",
       "          -0.5298]],\n",
       "\n",
       "        [[ 1.0896, -0.8622,  1.3571,  0.5579, -0.4322,  1.1513,  1.4784,\n",
       "          -0.9235],\n",
       "         [-1.1008, -0.6334,  0.2749, -0.1975,  0.0471,  0.3669,  0.7266,\n",
       "           0.4657],\n",
       "         [-0.8278, -0.1707, -1.5194, -0.2840, -1.8340,  1.5010, -1.5312,\n",
       "           1.3004]],\n",
       "\n",
       "        [[ 0.2462, -1.0931, -1.5495, -1.4534,  1.6599,  0.3497,  1.5365,\n",
       "          -1.3019],\n",
       "         [-0.1945,  0.5511,  0.4614, -1.3758, -1.5687,  0.0930,  0.5842,\n",
       "           0.7743],\n",
       "         [ 0.6928,  0.4164,  0.4343, -1.5143,  0.2965,  0.8982, -0.1242,\n",
       "           1.1810]],\n",
       "\n",
       "        [[ 0.5049,  0.7949, -0.1415,  0.0268, -0.4009,  0.8883, -0.3975,\n",
       "          -1.7064],\n",
       "         [ 0.4681,  0.9660, -0.7651, -1.2775, -1.3326,  0.7993,  1.5216,\n",
       "           0.8115],\n",
       "         [ 0.1326,  0.9304,  0.5280, -1.9095,  1.2970, -1.9442,  0.2108,\n",
       "          -0.0048]],\n",
       "\n",
       "        [[-0.7120, -2.1700, -0.0327, -0.0042,  0.3492, -0.4640, -0.3542,\n",
       "           1.8036],\n",
       "         [-0.8564,  0.4667,  0.0869,  1.8223, -0.4604,  0.7509, -0.6126,\n",
       "          -1.1521],\n",
       "         [ 0.1414,  0.3553,  1.3234,  0.6619,  0.1995, -0.6199,  1.3838,\n",
       "          -1.9064]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_norm.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b0ceb6-e87d-493a-8107-8a3121ca7b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml_algos_env",
   "language": "python",
   "name": ".ml_algos_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
