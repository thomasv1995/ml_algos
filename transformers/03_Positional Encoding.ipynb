{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6854923d-31d5-423e-b2f9-37aa2e1770cc",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=ZMxVe-HK174&list=PLTl9hO2Oobd97qfWC40gOSU8C0iu0m2l4&index=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145e121-ca45-4351-9120-6880707cc45e",
   "metadata": {},
   "source": [
    "Positional encodings are used for 3 reasons:  \n",
    "- periodicity: given a word vector, how much attention we should pay to 5, 10, 15 words after it\n",
    "- contrain values of the positional encodings between 1 and -1, avoids the problem during the calculation of attention whereby a word vector cannot attend to another word vector that is far away in terms of position. When calulcating the attention matrices, without bounded values for the positional encoding, a given vector will not be able to attend to other vectors that are far away from it and will not be able to derive any contetx from it\n",
    "- easy to extroplate for long sequences : positional encodings can be determined for words in sequences of lengths that have not been seen in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ae11d9-fd5c-4838-86e3-7a8e3795f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800bd172-7780-401e-a643-52f7505239d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 10\n",
    "# number of dimensions for PE\n",
    "d_model = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d6a0d0-929c-46cf-bd87-7c5372a93215",
   "metadata": {},
   "source": [
    "$$PE(position, 2i)=sin(\\frac{position}{10000\\frac{2i}{d_{model}}})$$ \n",
    "\n",
    "$$PE(position, 2i+1)=cos(\\frac{position}{10000\\frac{2i}{d_{model}}})$$ \n",
    "\n",
    "which can be re-written as :  \n",
    "\n",
    "$PE(position, i)=sin(\\frac{position}{10000\\frac{i}{d_{model}}})$, when $i$ is even  \n",
    "\n",
    "$PE(position, i)=cos(\\frac{position}{10000\\frac{i-1}{d_{model}}})$, when $i$ is odd\n",
    "\n",
    "*i* is the dimension index  \n",
    "*position* is the position of the word in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f4958e-01a3-4a6e-9194-eb5a7de95778",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_i = torch.arange(0, d_model, 2).float() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04064f96-afd4-480e-83f4-60db52b9a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_denominator = torch.pow(10000, even_i/d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02b7014f-38c7-49a0-a546-26a71eaafc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_i = torch.arange(1, d_model, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01802e3-0f00-40d5-b29a-0ab3aee70459",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_denominator = torch.pow(10000, (odd_i -1)/d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61da09a1-f5dc-4e52-8db3-0fdc585ba7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c00d32-f246-46e3-bc18-adb03c5e506b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f649ef36-8e29-44b0-9e04-7ecce01e3cbe",
   "metadata": {},
   "source": [
    "*even_denominator* and *odd_denominator* are the same, so we can do the same actions on just one of the variables and call the resulting variable *denominator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2888c6b6-20c1-4701-a2d4-271cafe866d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "951ce99b-8079-4b74-aa6a-cf9042d2bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = torch.arange(max_sequence_length, dtype=torch.float).reshape(max_sequence_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "734accdf-6aa7-4b6a-abc6-02d0b6c66e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_PE = torch.sin(position / denominator)\n",
    "odd_PE = torch.cos(position / denominator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd77614e-aae1-47d8-9d7b-8b93e66bceb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.8415,  0.0464,  0.0022],\n",
       "        [ 0.9093,  0.0927,  0.0043],\n",
       "        [ 0.1411,  0.1388,  0.0065],\n",
       "        [-0.7568,  0.1846,  0.0086],\n",
       "        [-0.9589,  0.2300,  0.0108],\n",
       "        [-0.2794,  0.2749,  0.0129],\n",
       "        [ 0.6570,  0.3192,  0.0151],\n",
       "        [ 0.9894,  0.3629,  0.0172],\n",
       "        [ 0.4121,  0.4057,  0.0194]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b3d813-6924-45be-8f2e-c0fca791eccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000],\n",
       "        [ 0.5403,  0.9989,  1.0000],\n",
       "        [-0.4161,  0.9957,  1.0000],\n",
       "        [-0.9900,  0.9903,  1.0000],\n",
       "        [-0.6536,  0.9828,  1.0000],\n",
       "        [ 0.2837,  0.9732,  0.9999],\n",
       "        [ 0.9602,  0.9615,  0.9999],\n",
       "        [ 0.7539,  0.9477,  0.9999],\n",
       "        [-0.1455,  0.9318,  0.9999],\n",
       "        [-0.9111,  0.9140,  0.9998]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "368fc87f-d001-44ae-9269-c4ed2636f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interleave the odd and even positional encodings\n",
    "stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
    "# provides vectors of positional encodings for each word (in this case, 10 words)\n",
    "PE = torch.flatten(stacked, start_dim=1, end_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22a9365-c13c-4031-9f8b-5f2b189e898c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff642b0a-9dde-4efe-89e5-cd0c87861ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model =d_model\n",
    "\n",
    "    def forward(self):\n",
    "        even_i = torch.arange(0, self.d_model, 2).float()\n",
    "        denominator = torch.pow(1000, even_id/self.model)\n",
    "        position = torch.arange(max_sequence_length, dtype=torch.float).reshape(max_sequence_length, 1)\n",
    "        even_PE = torch.sin(position / denominator)\n",
    "        odd_PE = torch.cos(position / denominator)\n",
    "        # interleave the odd and even positional encodings\n",
    "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
    "        # provides vectors of positional encodings for each word (in this case, 10 words)\n",
    "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "        return PE\n",
    "\n",
    "pe = PositionalEncoding(d_model=5, max_sequence_length=10)\n",
    "pe.forward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml_algos_env",
   "language": "python",
   "name": ".ml_algos_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
